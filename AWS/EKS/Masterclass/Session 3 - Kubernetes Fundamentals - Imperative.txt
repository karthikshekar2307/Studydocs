***** Kubernetes  architecture

Controller node components
- Kube-apiserver
- etcd
- kube scheduler
- Kube controller
(a) node controller
(b) replication controller
(c) endpoint controller
(d) service account and token controller
-  Cloud controller manager - component that embeds cloud-specific control logic.
(a) Node controller - for checking the clou provider to determine if a node has been deleted in the cloud after it stops responding
(b) Route controller - For setting up routes in the underlying cloud infrastructure
(c) Service controller - for creating, updating and deleting cloud provider load balancer.


Worker node
- Container runtime
- kubelet
- kube-proxy


***** Kubernetes vs EKS architecture
- Node groups
- No need to worry on any components


***** Kubernetes fundamentals
- pod
- replicaset
- deployments
- service

- Imperative: using kubectl command
- Declarative: YAML files or Helm charts


***** POD
container is encapsulated as POD.

***** Multipod container
- We can have multiple containers in a single POD, provided they are
not of same kind.
- Helper containers (side-car)
Data pullers
Data pushers
Proxies
- Communication
Two containers can easily communicate with each other

**** PODS demo
# kubectl get nodes
# kubectl get nodes -o wide

Create a POD
# kubectl run my-first-pod --image stacksimplify/kubenginx:1.0.0 --generator=run-pod/v1
--generator=run-pod/v1 -  to run pod as pod not deployment

Describe pod
# kubectl describe pod my-first

Delete pod
# kubectl delete pod my-first

***** Kubernetes NodePort service Introduction
We can expose an application running on a set of PODs using different types of service available in K8s
- ClusterIP
- NodePort
- LoadBalancer

- NodePort service
To access our appliction outside of K8s cluster, we can use NodePort service
Exposes the service on each Worker Node's IP at a static port (nothing but NodePort)
A ClusterIP service, to which the NodePort service routes, is automatically created
Port range - 30000-32767

Worker node port ---> cluster IP---> ContainerIP

# Create  a Pod
kubectl run <desired-pod-name> --image <Container-Image> --generator=run-pod/v1
kubectl run my-first-pod --image stacksimplify/kubenginx:1.0.0 --generator=run-pod/v1

# Expose Pod as a Service
kubectl expose pod <Pod-Name>  --type=NodePort --port=80 --name=<Service-Name>
kubectl expose pod my-first-pod  --type=NodePort --port=80 --name=my-first-service

# Get Service Info
kubectl get service
kubectl get svc

# Get Public IP of Worker Nodes
kubectl get nodes -o wide

Access the Application using Public IP
http://<node1-public-ip>:<Node-Port>

# Below command will fail when accessing the application, as service port (81) and container port (80) are different
kubectl expose pod my-first-pod  --type=NodePort --port=81 --name=my-first-service2     

# Expose Pod as a Service with Container Port (--taret-port)
kubectl expose pod my-first-pod  --type=NodePort --port=81 --target-port=80 --name=my-first-service3

# Get Service Info
kubectl get service
kubectl get svc

# Get Public IP of Worker Nodes
kubectl get nodes -o wide

Target port - port of container


***** Interact with POD and connect to container
# Get Pod Name
kubectl get po

# Dump Pod logs
kubectl logs <pod-name>
kubectl logs my-first-pod

# Stream pod logs with -f option and access application to see logs
kubectl logs <pod-name>
kubectl logs -f my-first-pod

- Connect to a Container in POD and execute commands
# Connect to Nginx Container in a POD
kubectl exec -it <pod-name> -- /bin/bash
kubectl exec -it my-first-pod -- /bin/bash

# Execute some commands in Nginx container
ls
cd /usr/share/nginx/html
cat index.html
exit


Running individual commands in a Container
kubectl exec -it <pod-name> env

# Sample Commands
kubectl exec -it my-first-pod env
kubectl exec -it my-first-pod ls
kubectl exec -it my-first-pod cat /usr/share/nginx/html/index.html

***** Delete Pod

# Get all Objects in default namespace
kubectl get all

# Delete Services
kubectl delete svc my-first-service
kubectl delete svc my-first-service2
kubectl delete svc my-first-service3

# Delete Pod
kubectl delete pod my-first-pod

# Get all Objects in default namespace
kubectl get all


***** Kubernetes ReplicaSet - Introduction
- High availability or reliability
- Scaling
- Load baalncing
- Labels and selectors

Replicaset's purpose is to maintain a stable set of replica pods running at any given time.
If our application crashes (any pod dies)
, replicaset will recreate the pod immediately to ensure the configured number of Pods at any given time.

Kubernetes provides load balancer out of the box

provides labels and selectors


***** Kubernetes replicaset - create ReplicaSet
- No imparative way (need to use yaml)

Create ReplicaSet
# kubectl create -f replicaset-demo.yml

replicaset-demo.yml
apiVersion: apps/v1
kind: ReplicaSet
metadata:
  name: my-helloworld-rs
  labels:
    app: my-helloworld
spec:
  replicas: 3
  selector:
    matchLabels:
      app: my-helloworld
  template:
    metadata:
      labels:
        app: my-helloworld
    spec:
      containers:
      - name: my-helloworld-app
        image: stacksimplify/kube-helloworld:1.0.0

List ReplicaSets
Get list of ReplicaSets
# kubectl get replicaset
# kubectl get rs

Describe ReplicaSet
Describe the newly created ReplicaSet
# kubectl describe rs/<replicaset-name>

# kubectl describe rs/my-helloworld-rs
[or]
# kubectl describe rs my-helloworld-rs

Get list of Pods
#Get list of Pods
# kubectl get pods
# kubectl describe pod <pod-name>

Get list of Pods with Pod IP and Node in which it is running
# kubectl get pods -o wide

Verify the Owner of the Pod
Verify the owner reference of the pod.
Verify under "name" tag under "ownerReferences". We will find the replicaset name to which this pod belongs to.
# kubectl get pods <pod-name> -o yaml
# kubectl get pods my-helloworld-rs-c8rrj -o yaml 

***** 
Step-03: Expose ReplicaSet as a Service
Expose ReplicaSet with a service (NodePort Service) to access the application externally (from internet)
Expose ReplicaSet as a Service
# kubectl expose rs <ReplicaSet-Name>  --type=NodePort --port=80 --target-port=8080 --name=<Service-Name-To-Be-Created>
# kubectl expose rs my-helloworld-rs  --type=NodePort --port=80 --target-port=8080 --name=my-helloworld-rs-service

Get Service Info
# kubectl get service
# kubectl get svc

Get Public IP of Worker Nodes
# kubectl get nodes -o wide

Step-04: Test Replicaset Reliability or High Availability
Test how the high availability or reliability concept is achieved automatically in Kubernetes
Whenever a POD is accidentally terminated due to some application issue, ReplicaSet should auto-create that Pod to maintain desired number of Replicas configured to achive High Availability.
To get Pod Name
# kubectl get pods

Delete the Pod
# kubectl delete pod <Pod-Name>

Verify the new pod got created automatically
# kubectl get pods   (Verify Age and name of new pod)

Step-05: Test ReplicaSet Scalability feature
Test how scalability is going to seamless & quick
Update the replicas field in replicaset-demo.yml from 3 to 6.
# Before change
spec:
  replicas: 3

# After change
spec:
  replicas: 6
Update the ReplicaSet
# Apply latest changes to ReplicaSet
kubectl replace -f replicaset-demo.yml

# Verify if new pods got created
kubectl get pods -o wide

Step-06: Delete ReplicaSet & Service
Delete ReplicaSet
# Delete ReplicaSet
kubectl delete rs <ReplicaSet-Name>

# Sample Commands
kubectl delete rs/my-helloworld-rs
[or]
kubectl delete rs my-helloworld-rs

# Verify if ReplicaSet got deleted
kubectl get rs
Delete Service created for ReplicaSet
# Delete Service
kubectl delete svc <service-name>

# Sample Commands
kubectl delete svc my-helloworld-rs-service
[or]
kubectl delete svc/my-helloworld-rs-service

# Verify if Service got deleted
kubectl get svc


***** Kubernetes deployment - Introduction
Deployment features
- Create a deployment to rollout a Replicaset
- Updating the deployment
- Rolling back a deployment
- Scaling a deployment
- Pausig and resuming a deployment
- Deployment status
- Cleanup policy
- Canary deployment

Step-02: Create Deployment
Create Deployment to rollout a ReplicaSet
Verify Deployment, ReplicaSet & Pods
Docker Image Location: https://hub.docker.com/repository/docker/stacksimplify/kubenginx
# Create Deployment
kubectl create deployment <Deplyment-Name> --image=<Container-Image>
kubectl create deployment my-first-deployment --image=stacksimplify/kubenginx:1.0.0 

# Verify Deployment
kubectl get deployments
kubectl get deploy 

# Describe Deployment
kubectl describe deployment <deployment-name>
kubectl describe deployment my-first-deployment

# Verify ReplicaSet
kubectl get rs

# Verify Pod
kubectl get po

Step-03: Scaling a Deployment
Scale the deployment to increase the number of replicas (pods)
# Scale Up the Deployment
kubectl scale --replicas=20 deployment/<Deployment-Name>
kubectl scale --replicas=20 deployment/my-first-deployment 

# Verify Deployment
kubectl get deploy

# Verify ReplicaSet
kubectl get rs

# Verify Pods
kubectl get po

# Scale Down the Deployment
kubectl scale --replicas=10 deployment/my-first-deployment 
kubectl get deploy

Step-04: Expose Deployment as a Service
Expose Deployment with a service (NodePort Service) to access the application externally (from internet)
# Expose Deployment as a Service
kubectl expose deployment <Deployment-Name>  --type=NodePort --port=80 --target-port=80 --name=<Service-Name-To-Be-Created>
kubectl expose deployment my-first-deployment --type=NodePort --port=80 --target-port=80 --name=my-first-deployment-service

# Get Service Info
kubectl get svc
Observation: Make a note of port which starts with 3 (Example: 80:3xxxx/TCP). Capture the port 3xxxx and use it in application URL below. 

# Get Public IP of Worker Nodes
kubectl get nodes -o wide
Observation: Make a note of "EXTERNAL-IP" if your Kubernetes cluster is setup on AWS EKS.


****** Kubernetes deployment - Update deployment using set-image option
Update Deployment
Observation: Please Check the container name in spec.container.name yaml output and make a note of it and replace in kubectl set image command

# Get Container Name from current deployment
kubectl get deployment my-first-deployment -o yaml

# Update Deployment - SHOULD WORK NOW
kubectl set image deployment/<Deployment-Name> <Container-Name>=<Container-Image> --record=true
kubectl set image deployment/my-first-deployment kubenginx=stacksimplify/kubenginx:2.0.0 --record=true

Verify Rollout Status (Deployment Status)
Observation: By default, rollout happens in a rolling update model, so no downtime.
# Verify Rollout Status 
kubectl rollout status deployment/my-first-deployment

# Verify Deployment
kubectl get deploy

Describe Deployment
Observation:
Verify the Events and understand that Kubernetes by default do "Rolling Update" for new application releases.
With that said, we will not have downtime for our application.
# Descibe Deployment
kubectl describe deployment my-first-deployment

***** Editing deployment using kubectl Edit
Step-00: Introduction
We can rollback a deployment in two ways.
Previous Version
Specific Version
Step-01: Rollback a Deployment to previous version
Check the Rollout History of a Deployment
# List Deployment Rollout History
kubectl rollout history deployment/<Deployment-Name>
kubectl rollout history deployment/my-first-deployment  
Verify changes in each revision
Observation: Review the "Annotations" and "Image" tags for clear understanding about changes.
# List Deployment History with revision information
kubectl rollout history deployment/my-first-deployment --revision=1
kubectl rollout history deployment/my-first-deployment --revision=2
kubectl rollout history deployment/my-first-deployment --revision=3
Rollback to previous version
Observation: If we rollback, it will go back to revision-2 and its number increases to revision-4
# Undo Deployment
kubectl rollout undo deployment/my-first-deployment

# List Deployment Rollout History
kubectl rollout history deployment/my-first-deployment  
Verify Deployment, Pods, ReplicaSets
kubectl get deploy
kubectl get rs
kubectl get po
kubectl describe deploy my-first-deployment
Access the Application using Public IP
We should see Application Version:V2 whenever we access the application in browser
# Get NodePort
kubectl get svc
Observation: Make a note of port which starts with 3 (Example: 80:3xxxx/TCP). Capture the port 3xxxx and use it in application URL below. 

# Get Public IP of Worker Nodes
kubectl get nodes -o wide
Observation: Make a note of "EXTERNAL-IP" if your Kubernetes cluster is setup on AWS EKS.

# Application URL
http://<worker-node-public-ip>:<Node-Port>
Step-02: Rollback to specific revision
Check the Rollout History of a Deployment

# List Deployment Rollout History
kubectl rollout history deployment/<Deployment-Name>
kubectl rollout history deployment/my-first-deployment 

Rollback to specific revision
# Rollback Deployment to Specific Revision
kubectl rollout undo deployment/my-first-deployment --to-revision=3
List Deployment History
Observation: If we rollback to revision 3, it will go back to revision-3 and its number increases to revision-5 in rollout history

# List Deployment Rollout History
kubectl rollout history deployment/my-first-deployment  
Access the Application using Public IP
We should see Application Version:V3 whenever we access the application in browser

# Get NodePort
kubectl get svc
Observation: Make a note of port which starts with 3 (Example: 80:3xxxx/TCP). Capture the port 3xxxx and use it in application URL below. 

# Get Public IP of Worker Nodes
kubectl get nodes -o wide
Observation: Make a note of "EXTERNAL-IP" if your Kubernetes cluster is setup on AWS EKS.

# Application URL
http://<worker-node-public-ip>:<Node-Port>
Step-03: Rolling Restarts of Application
Rolling restarts will kill the existing pods and recreate new pods in a rolling fashion.
# Rolling Restarts
kubectl rollout restart deployment/<Deployment-Name>
kubectl rollout restart deployment/my-first-deployment

# Get list of Pods
kubectl get po



***** Pause and resume deployments
Step-00: Introduction
Why do we need Pausing & Resuming Deployments?
If we want to make multiple changes to our Deployment, we can pause the deployment make all changes and resume it.
We are going to update our Application Version from V3 to V4 as part of learning "Pause and Resume Deployments"
Step-01: Pausing & Resuming Deployments
Check current State of Deployment & Application

# Check the Rollout History of a Deployment
kubectl rollout history deployment/my-first-deployment  
Observation: Make a note of last version number

# Get list of ReplicaSets
kubectl get rs
Observation: Make a note of number of replicaSets present.

# Access the Application 
http://<worker-node-ip>:<Node-Port>
Observation: Make a note of application version
Pause Deployment and Two Changes
# Pause the Deployment
kubectl rollout pause deployment/<Deployment-Name>
kubectl rollout pause deployment/my-first-deployment

# Update Deployment - Application Version from V3 to V4
kubectl set image deployment/my-first-deployment kubenginx=stacksimplify/kubenginx:4.0.0 --record=true

# Check the Rollout History of a Deployment
kubectl rollout history deployment/my-first-deployment  
Observation: No new rollout should start, we should see same number of versions as we check earlier with last version number matches which we have noted earlier.

# Get list of ReplicaSets
kubectl get rs
Observation: No new replicaSet created. We should have same number of replicaSets as earlier when we took note. 

# Make one more change: set limits to our container
kubectl set resources deployment/my-first-deployment -c=kubenginx --limits=cpu=20m,memory=30Mi
Resume Deployment
# Resume the Deployment
kubectl rollout resume deployment/my-first-deployment

# Check the Rollout History of a Deployment
kubectl rollout history deployment/my-first-deployment  
Observation: You should see a new version got created

# Get list of ReplicaSets
kubectl get rs
Observation: You should see new ReplicaSet.
Access Application
# Access the Application 
http://<node1-public-ip>:<Node-Port>
Observation: You should see Application V4 version
Step-02: Clean-Up
# Delete Deployment
kubectl delete deployment my-first-deployment

# Delete Service
kubectl delete svc my-first-deployment-service

# Get all Objects from Kubernetes default namespace
kubectl get all


***** Kubernetes Services
Step-01: Introduction to Services
Service Types:

ClusterIp - USed for communication between applicatiins inside k8s cluster
NodePort - Used for accessing applications outside of k8s cluster using woker node ports
LoadBalancer - Primarily used for cloud providers to integrate with theirt load balancer services
Ingress - advanced load balancer which provides context path based routing, SSL, SSL redirect and many more
External name - To access externally hosted apps in k8s cluster (example: access AWS RDS databae endpoint by appication present insde k8s cluster)


We are going to look in to ClusterIP and NodePort in this section with a detailed example.
LoadBalancer Type is primarily for cloud providers and it will differ cloud to cloud, so we will do it accordingly (per cloud basis)
ExternalName doesn't have Imperative commands and we need to write YAML definition for the same, so we will look in to it as and when it is required in our course.

Step-02: ClusterIP Service - Backend Application Setup
Create a deployment for Backend Application (Spring Boot REST Application)
Create a ClusterIP service for load balancing backend application.
# Create Deployment for Backend Rest App
kubectl create deployment my-backend-rest-app --image=stacksimplify/kube-helloworld:1.0.0 
kubectl get deploy

# Create ClusterIp Service for Backend Rest App
kubectl expose deployment my-backend-rest-app --port=8080 --target-port=8080 --name=my-backend-service
kubectl get svc
Observation: We don't need to specify "--type=ClusterIp" because default setting is to create ClusterIp Service. 
Important Note: If backend application port (Container Port: 8080) and Service Port (8080) are same we don't need to use --target-port=8080 but for avoiding the confusion i have added it. Same case applies to frontend application and service.

Backend HelloWorld Application Source kube-helloworld

Step-03: NodePort Service - Frontend Application Setup
We have implemented NodePort Service multiple times so far (in pods, replicasets and deployments), even then we are going to implement one more time to get a full architectural view in relation with ClusterIp service.
Create a deployment for Frontend Application (Nginx acting as Reverse Proxy)
Create a NodePort service for load balancing frontend application.
Important Note: In Nginx reverse proxy, ensure backend service name my-backend-service is updated when you are building the frontend container. We already built it and put ready for this demo (stacksimplify/kube-frontend-nginx:1.0.0)
Nginx Conf File
server {
    listen       80;
    server_name  localhost;
    location / {
    # Update your backend application Kubernetes Cluster-IP Service name  and port below      
    # proxy_pass http://<Backend-ClusterIp-Service-Name>:<Port>;      
    proxy_pass http://my-backend-service:8080;
    }
    error_page   500 502 503 504  /50x.html;
    location = /50x.html {
        root   /usr/share/nginx/html;
    }
}
Docker Image Location: https://hub.docker.com/repository/docker/stacksimplify/kube-frontend-nginx
Frontend Nginx Reverse Proxy Application Source kube-frontend-nginx
# Create Deployment for Frontend Nginx Proxy
kubectl create deployment my-frontend-nginx-app --image=stacksimplify/kube-frontend-nginx:1.0.0 
kubectl get deploy

# Create ClusterIp Service for Frontend Nginx Proxy
kubectl expose deployment my-frontend-nginx-app  --type=NodePort --port=80 --target-port=80 --name=my-frontend-service
kubectl get svc

# Capture IP and Port to Access Application
kubectl get svc
kubectl get nodes -o wide
http://<node1-public-ip>:<Node-Port>/hello

# Scale backend with 10 replicas
kubectl scale --replicas=10 deployment/my-backend-rest-app

# Test again to view the backend service Load Balancing
http://<node1-public-ip>:<Node-Port>/hello

Kubernetes - Services
Step-01: Introduction to Services
Service Types
ClusterIp
NodePort
LoadBalancer
ExternalName
We are going to look in to ClusterIP and NodePort in this section with a detailed example.
LoadBalancer Type is primarily for cloud providers and it will differ cloud to cloud, so we will do it accordingly (per cloud basis)
ExternalName doesn't have Imperative commands and we need to write YAML definition for the same, so we will look in to it as and when it is required in our course.
Step-02: ClusterIP Service - Backend Application Setup
Create a deployment for Backend Application (Spring Boot REST Application)
Create a ClusterIP service for load balancing backend application.
# Create Deployment for Backend Rest App
kubectl create deployment my-backend-rest-app --image=stacksimplify/kube-helloworld:1.0.0 
kubectl get deploy

# Create ClusterIp Service for Backend Rest App
kubectl expose deployment my-backend-rest-app --port=8080 --target-port=8080 --name=my-backend-service
kubectl get svc
Observation: We don't need to specify "--type=ClusterIp" because default setting is to create ClusterIp Service. 
Important Note: If backend application port (Container Port: 8080) and Service Port (8080) are same we don't need to use --target-port=8080 but for avoiding the confusion i have added it. Same case applies to frontend application and service.

Backend HelloWorld Application Source kube-helloworld

Step-03: NodePort Service - Frontend Application Setup
We have implemented NodePort Service multiple times so far (in pods, replicasets and deployments), even then we are going to implement one more time to get a full architectural view in relation with ClusterIp service.
Create a deployment for Frontend Application (Nginx acting as Reverse Proxy)
Create a NodePort service for load balancing frontend application.
Important Note: In Nginx reverse proxy, ensure backend service name my-backend-service is updated when you are building the frontend container. We already built it and put ready for this demo (stacksimplify/kube-frontend-nginx:1.0.0)
Nginx Conf File
server {
    listen       80;
    server_name  localhost;
    location / {
    # Update your backend application Kubernetes Cluster-IP Service name  and port below      
    # proxy_pass http://<Backend-ClusterIp-Service-Name>:<Port>;      
    proxy_pass http://my-backend-service:8080;
    }
    error_page   500 502 503 504  /50x.html;
    location = /50x.html {
        root   /usr/share/nginx/html;
    }
}
Docker Image Location: https://hub.docker.com/repository/docker/stacksimplify/kube-frontend-nginx
Frontend Nginx Reverse Proxy Application Source kube-frontend-nginx
# Create Deployment for Frontend Nginx Proxy
kubectl create deployment my-frontend-nginx-app --image=stacksimplify/kube-frontend-nginx:1.0.0 
kubectl get deploy

# Create ClusterIp Service for Frontend Nginx Proxy
kubectl expose deployment my-frontend-nginx-app  --type=NodePort --port=80 --target-port=80 --name=my-frontend-service
kubectl get svc

# Capture IP and Port to Access Application
kubectl get svc
kubectl get nodes -o wide
http://<node1-public-ip>:<Node-Port>/hello

# Scale backend with 10 replicas
kubectl scale --replicas=10 deployment/my-backend-rest-app

# Test again to view the backend service Load Balancing
http://<node1-public-ip>:<Node-Port>/hello
Pending Topics
We will look in tho these items when we progress in to course on that respective cloud provider
LoadBalancer
ExternalName