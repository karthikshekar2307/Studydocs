Session 5 - Cluster Maintenance
---------------------------------

***** Operating system upgrades
In a kubernetes cluster if a node goes down and comes back immediately within 5 mins. Kubernetes will make the POD available once again.
If the Pods are part of replicaset, the pods will be launched on other nodes.
If the node is down for a longer time than 5 mins, kubernetes will mark node as dead and terminate pods.
The time it wait for PODS to comeback online is known as - POD eviction time out and it is set in controller manager with default value of 5 mins.
# kube-controller-manager --pod-eviction-timeout=5m0s


When a node comes back online after POD eviction time out, it comes up blank without any PODs scheduled on it.

The safe way is to purposefully, drain the node, so PODs are placed in other nodes. (terminated and recreated). Node is marked as unschedulable.

To drain the node
# kubectl drain node-1

To regain access to the node after it comes back, we need to "uncordon" the node
# kubectl uncordon node-1

Marks the node unschedulable
# kubectl cordon node-2


***** Practise test
To drain and unschedule the node
# kubectl drain node01 --ignore-daemonsets


***** Kubernetes releases

To get versions
# kubectl get nodes (view the version)

Version consists of
v1.11.3
v1 - Major version
11 - Minor version (released every few months)
3 - Patch (released often)

Alfa and beta releases
alfa - all new release
then its Beta (well tested)
then its stable release

- References
https://kubernetes.io/docs/concepts/overview/kubernetes-api/

Here is a link to kubernetes documentation if you want to learn more about this topic (You don't need it for the exam though):

https://github.com/kubernetes/community/blob/master/contributors/devel/sig-architecture/api-conventions.md

https://github.com/kubernetes/community/blob/master/contributors/devel/sig-architecture/api_changes.md


***** Cluster Upgrade process
Different components will have their versions. We will keep dependency on external componets like ETCD cluster and CoreDNS

Its not necessary for all compontnes to have same version.

kubeapi server is the primary component in controlplane and that is the component that all other components talk to. None of the other components should be higher than kubeapi server.

The controller manager and scheduler can be one version lower.

kubelet and kube-proxy can be at two version lower.

None of them can be of higher version than API server.

We can upgrade component by component if required.

When to upgrade?
- At any time, kubernetes supports up to 3 previous minor version releases. It is best to upgrade before new third minor version release.

How to upgrade?
- Its not recommended to upgrade directly to recent version/release. You need to go step by step at a time.

Upgrade process
- if its a managed (AWS, GCP), its few clicks

- if kubeadm
# kubectl upgrade plan
# kubectl upgrade apply

- the hard way
Need to manually upgrade one by one.

Using Kubeadm
- Upgrade master and then, upgrade worker

When the master is being upgraded, the controlplane components such as API server, scheduler and controller manager go down briefly. Master going down does not mean that services and workers are impacted.
All workloads hosted on worker node continue to serve users as normal. Since the master is down, all management fuctions are down. You cannot control cluster using kubectl or kube API. 

There are different strategies available to upgrade worker nodes.
- To upgrade all of them at once. In this scenario, users are unable to access applications.
- Upgrade one node at a time. Workloads move to other nodes in cluster
- Add new nodes to cluster with new version one by one.

How upgrade is done
kubeadm has an upgrade command
# kubeadm upgrade plan
(kubeadm does not install or upgrade kubelet)
- kubeadm tool must be upgraded before update

# apt-get upgrade -y kubeadm=1.12.0-00
# kubeadm upgrade apply v1.12.0

upgrade kubelet
# apt-get upgrade -y kubelet=1.12.0-00
# systemctl restart kubelet

To upgrade nodes
- drain node one by one
- upgrade kubeadm, kubelet
# apt-get upgrade -y kubeadm=1.12.0-00
# apt-get upgrade -y kubelet=1.12.0-00
# kubeadm upgrade node config --kubelet-version v1.12.0
# systemctl restart kubelet


***** Demo
"Search for Kubernetes upgrade"

# kubectl get nodes

# kubeadm token list

# kubectl get pods -A (To see all nodes on all namespaces)

# kubectl get nodes (confirm version)

# apt update

# apt-mark unhold kubeadm && \
apt get update && apt-get install -y kubeadm=1.18.17-00 && \
apt-mark hold kubeadm

# kubeadm version

# kubeadm upgrade plan

# kubeadm upgrade apply 1.19.6

# kubeadm upgrade plan

# kubectl get nodes

upgrade kubelet
# kubectl drain controlplane

# apt-mark unhold kubelet kubectl && \
apt-get update && apt-get install -y kubelet=1.19.0-00 kubectl=1.19.x-00 && \
apt-mark hold kubelet kubectl

# kubectl uncordon controlplane

- To upgrade worker nodes
(a) upgrade kubeadm
# apt-mark unhold kubeadm && \
apt get update && apt-get install -y kubeadm=1.19.x-00 && \
apt-mark hold kubeadm

(b) upgrade kubelet config
# kubeadm upgrade node config --kubelet-version v1.19.0

(c) drain node (need to be run on controlplane)
# kubectl drain node01 --ignore-daemonsets

(d) upgrade kubelet and kubectl

(e) reload and restart kubelet

(f) Uncordon the node.


***** Solution
-To see version
# kubectl get nodes
# kubectl version --short

-To see number of nodes
# kubectl get nodes

- To see latest stable version
# kubeadm upgrade plan

- Upgrade master
# kubeadm version
# apt install kubeadm=1.18.0-00
# kubeadm version
# kubeadm upgrade apply v1.18.0
# kubectl version --short
# kubectl get nodes
# apt install kubelet=1.18.0-00
# kubectl get nodes

- Upgrade worker
# kubectl drain node01
# ssh node01
node01$ apt install kubeadm=1.18.0-00
node01$ kubeadm version
node01$ kubeadm upgrade apply v1.18.0
node01$ kubectl version --short
node01$ apt install kubelet=1.18.0
node01$ exit
# kubectl get nodes
# kubectl uncordon node01


***** Backup and restore
Backup Candidates
- Resource configurations
- ETCD cluster
- Persistent volumes

- Resource confgurations
Declarative -> Github
# kubectl get all --all-namespaces -o yaml > all-deploy-services.yaml
3rd party tools
- Velero (using kubernetes API)

- ETCD cluster
details of state of kubernetes cluster
hosted on master node
etcd.service (--data-dir)
take snapshot
# ETCDCTL_API=3 etcdctl \
     snapshot save snapshot.db

# ls
snapshot.db

To view status
# ETCDCTL_API=3 etcdctl \
    snapshot status snapshot.db

To restore
- stop service
# service kube-apiserver stopped


# ETCDCTL_API=3 etcdctl \
    snapshot restore snapshot.db \
    --data-dir /var/lib/etcd-from-backup

When etcd is restores it creates a new cluster configuration and configures the members of ETCD as new members to new cluster. This is to ensure that new member is not joined to cluster accidentally.

then use the etcd.service file to use new data directory
etcd.service
--data-dir=/var/lib/etcd-from-backup

Then, reload the service daemon
# systemctl daemon-reload

Restart  etcd service
# service etcd restart

Start kubeapi server service
# service kube-apiserver start


***** Working with ETCDCTL
etcdctl is a command line client for etcd.

In all our Kubernetes Hands-on labs, the ETCD key-value database is deployed as a static pod on the master. The version used is v3.
To make use of etcdctl for tasks such as back up and restore, make sure that you set the ETCDCTL_API to 3.

You can do this by exporting the variable ETCDCTL_API prior to using the etcdctl client. This can be done as follows:
export ETCDCTL_API=3

On the Master Node:
To see all the options for a specific sub-command, make use of the -h or --help flag.

For example, if you want to take a snapshot of etcd, use:
etcdctl snapshot save -h and keep a note of the mandatory global options.

Since our ETCD database is TLS-Enabled, the following options are mandatory:
--cacert                                                verify certificates of TLS-enabled secure servers using this CA bundle
--cert                                                    identify secure client using this TLS certificate file
--endpoints=[127.0.0.1:2379]          This is the default as ETCD is running on master node and exposed on localhost 2379.
--key                                                      identify secure client using this TLS key file


Similarly use the help option for snapshot restore to see all available options for restoring the backup.
# etcdctl snapshot restore -h
For a detailed explanation on how to make use of the etcdctl command line tool and work with the -h flags, check out the solution video for the Backup and Restore Lab.


**** Practise test
To get the version of ETCD
# kubectl describe pod etcd-controlplane -n kube-system

Where is the ca-cert located
# kubectl -n kube-system describe pod etcd-controlplane | grep '\--cert-file'

Where is the ETCD CA Certificate file located?
# kubectl -n kube-system describe pod etcd-controlplane | grep '\--trusted-ca-file'

Create a new backup
# ETCDCTL_API=3 etcdctl --endpoints=https://[127.0.0.1]:2379 \
> --cacert=/etc/kubernetes/pki/etcd/ca.crt \
> --cert=/etc/kubernetes/pki/etcd/server.crt \
> --key=/etc/kubernetes/pki/etcd/server.key \
> snapshot save /opt/snapshot-pre-boot.db
Snapshot saved at /opt/snapshot-pre-boot.db

Restore snapshot
# ETCDCTL_API=3 etcdctl  --data-dir /var/lib/etcd-from-backup \
snapshot restore /opt/snapshot-pre-boot.db


Note: In this case, we are restoring the snapshot to a different directory but in the same server where we took the backup (the controlplane node) As a result, the only required option for the restore command is the --data-dir.


Next, update the /etc/kubernetes/manifests/etcd.yaml:

We have now restored the etcd snapshot to a new path on the controlplane - /var/lib/etcd-from-backup, so, the only change to be made in the YAML file, is to change the hostPath for the volume called etcd-data from old directory (/var/lib/etcd) to the new directory /var/lib/etcd-from-backup.

  volumes:
  - hostPath:
      path: /var/lib/etcd-from-backup
      type: DirectoryOrCreate
    name: etcd-data
With this change, /var/lib/etcd on the container points to /var/lib/etcd-from-backup on the controlplane (which is what we want)

When this file is updated, the ETCD pod is automatically re-created as this is a static pod placed under the /etc/kubernetes/manifests directory.

Note: as the ETCD pod has changed it will automatically restart, and also kube-controller-manager and kube-scheduler. Wait 1-2 to mins for this pods to restart. You can run a watch "docker ps | grep etcd" command to see when the ETCD pod is restarted.

Note2: If the etcd pod is not getting Ready 1/1, then restart it by kubectl delete pod -n kube-system etcd-controlplane and wait 1 minute.

Note3: This is the simplest way to make sure that ETCD uses the restored data after the ETCD pod is recreated. You don't have to change anything else.

If you do change --data-dir to /var/lib/etcd-from-backup in the YAML file, make sure that the volumeMounts for etcd-data is updated as well, with the mountPath pointing to /var/lib/etcd-from-backup (THIS COMPLETE STEP IS OPTIONAL AND NEED NOT BE DONE FOR COMPLETING THE RESTORE)

***** References
https://kubernetes.io/docs/tasks/administer-cluster/configure-upgrade-etcd/#backing-up-an-etcd-cluster

https://github.com/etcd-io/etcd/blob/master/Documentation/op-guide/recovery.md

https://www.youtube.com/watch?v=qRPNuT080Hk
